# -*- coding: utf-8 -*-
"""Módulo 2 Implementación de una técnica de aprendizaje máquina sin el uso de un framework_A01177643.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z3hyh356yf7US1lqXBR-yxaHC6uXrktZ

## **Módulo 2 Implementación de una técnica de aprendizaje máquina sin el uso de un framework**
*(Portafolio Implementación)*

Andrea Galicia Jimenez

A01177643
"""

#Importamos las librerias que usaremos
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.pyplot import cm

"""1. Escogemos una base de datos con la cual trabajaremos. Para este caso se escogio una base de datos de la F1 la cual nos muestra diferentes datos como lo son los podiums de cada piloto, sus puntos acomulados por temporada, el circuito que se corrio, las condiciones climatologicas, etc."""

# Cargamos datos desde el archivo CSV
data = pd.read_csv("Salary_dataset.csv")
data

# Asignamos X y Y
X = data['YearsExperience'].values
y0 = data['Salary'].values

# Graficamos los datos
plt.scatter(X, y0, marker='o', c='r')
plt.xlabel('X')
plt.ylabel('Y')

"""## **Implementacion del modelo - Regresion Lineal**"""

#Implementamos el modelo de regresion lineal para ajustar los datos
def adjust_params(X, y, w, b, alpha):
    dl_dw = 0.0
    dl_db = 0.0
    N = len(X)
    for i in range(N):
        dl_dw += -2*X[i]*(y[i] - (w*X[i] + b))
        dl_db += -2*(y[i] - (w*X[i] + b))

    w = w - (1/float(N)) * dl_dw * alpha
    b = b - (1/float(N)) * dl_db * alpha
    return w, b

def train_and_display(X, y, w, b, alpha, epochs, x_range_plot):
    losses = []  # Pérdidas de cada época
    for e in range(epochs):
        w, b = adjust_params(X, y, w, b, alpha)
        avg_loss_ = calculate_avg_loss(X, y, w, b)
        losses.append(avg_loss_)
        print("Epoch {}: Loss: {:.4f} | w: {:.4f}, b: {:.4f}".format(e, avg_loss_, w, b))

        # Plots
        if e == epochs - 1:
            x_vals = np.array(range(0, x_range_plot))
            y_vals = (x_vals * w) + b
            plt.scatter(x=X, y=y)
            plt.plot(y_vals, c='r')
            plt.title("Epoch {} | Loss: {:.4f} | w: {:.4f}, b: {:.4f}".format(e, avg_loss_, w, b))
            plt.show()
    plot_loss_curve(losses)

    return w, b

def calculate_avg_loss(X, y, w, b):
    N = len(X)
    total_error = 0.0
    for i in range(N):
        total_error += (y[i] - (w*X[i] + b))**2
    return total_error / float(N)

def plot_loss_curve(losses):
    plt.plot(losses)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Loss Curve')
    plt.show()

"""Evaluamos al modelo con unos parametros iniciales sin tomar en cuenta si son los correctos o no:"""

# Evaluamos al modelo
# Parámetros iniciales
initial_w = 0.0
initial_b = 0.0
learning_rate = 0.0001
num_epochs = 10
x_range_plot = 10
num_folds = 5

# Entrenar y visualizar
train_and_display(X, y0, initial_w, initial_b, learning_rate, num_epochs, x_range_plot)

"""Mejoramos al modelo al entrenarlo y modificar sus parametros:"""

# Buscamos un aproximado a prueba y error de una mejora de los parametros para mejorar le modelo
initial_w = 0.5
initial_b = 1.0
learning_rate = 0.01
num_epochs = 100
x_range_plot = 10
num_folds = 5

# Dividir los datos en k conjuntos
indices = np.arange(len(X))
np.random.shuffle(indices)
fold_size = len(X) // num_folds

# Listas para almacenar pérdidas y coeficientes
losses = []
coefficients = []

# Ciclo de validación cruzada
for k in range(num_folds):
    # Dividir en conjunto de entrenamiento y prueba
    val_indices = indices[k * fold_size : (k + 1) * fold_size]
    train_indices = np.concatenate((indices[:k * fold_size], indices[(k + 1) * fold_size:]))
    X_train, y_train = X[train_indices], y0[train_indices]
    X_val, y_val = X[val_indices], y0[val_indices]

    # Entrenar el modelo
    w, b = initial_w, initial_b
    for _ in range(num_epochs):
        w, b = adjust_params(X_train, y_train, w, b, learning_rate)

    # Calcular pérdida en conjunto de validación
    avg_loss_val = calculate_avg_loss(X_val, y_val, w, b)
    losses.append(avg_loss_val)
    coefficients.append((w, b))

# Elegir el mejor conjunto de coeficientes según la pérdida
best_index = np.argmin(losses)
best_w, best_b = coefficients[best_index]

def predict_value(x, w, b):
    return w * x + b

# Graficar los datos y el mejor modelo
plt.scatter(X, y0, color='blue', label='Datos reales')
y_pred_best = predict_value(X, best_w, best_b)
plt.plot(X, y_pred_best, color='red', label='Mejor Modelo')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Regresión Lineal Mejorada')
plt.legend()
plt.show()

"""## Analisis:
A lo largo de esta asignatura se realizaron diferentes procedimientos para obtener el objetivo de poder dar una idea de prediccion sobre el aumento del salario con respecto a los años de experiencia. Mas alla de un modelo predictivo, el objetivo fue principalmente poder entender el proceso de la creacion de un modelo de regresion lineal sin la necesidad de utilizar apoyos extras de machine learning como lo son las librerias que el sistema nos ofrece.

Se decidio implemengtar esta base de datos ya que es una de las mas usadas del sitio Kaggle por su sencillez en entendimiento pero tambien su uso efectivo para poder obervar una verdadera mejora en los datos.

A simples palabras, podemos decir que el proceos fue el siguiente:
1. Se descargo la base de datos y se exploro un poco para visualizar que datos son los que tiene
2. Creamos funciones para tareas especificas dentro de la implementacion de la regresion lineal sobre los datos (ya que este fue el modelo que se utilizo)
3. Tanteamos al modelo con unos parametros iniciales totalmente desconocidos e inclusive de 0 para solamente darnos una idea de que tanto de requeriria mejorar el modelo
4. Se entreno al modelo para poder mejorar la perdida en los epocs y en si los datos en la regresion lineal. Para este caso la busqueda de los mejores parametros fue manual y a prueba y error como visto en clase.

## Conclusion:
En conclusion, podemos notar que el modelo si tuvo una mejora notoria al entrenarlo de manera totalmente manual y entendiendo que parametros se ajustaban mejor a este.

La regresión lineal es uno de los conceptos fundamentales en el campo del aprendizaje automático y estadísticas. Permite modelar y comprender las relaciones lineales entre variables, lo que es esencial para hacer predicciones y tomar decisiones basadas en datos. A lo largo de este proceso, pudimos notar que el modelo si tuvo una mejora notoria al entrenarlo de manera totalmente manual y entendiendo que parametros se ajustaban mejor a este. Gracias a este proceso de logro entender un poco mas sobre el proceso que conlleva la aplicacion de este modelo junto con su ajuste para asi poder no solo aplicar lo visto en clase, si no que tambien lo aprendido practicamente.



*(Para este trabajo se utilizo la libreria "Salary_dataset.csv" de Kaggle y se utilizo el colab visto en clase como apoyo)*



"""